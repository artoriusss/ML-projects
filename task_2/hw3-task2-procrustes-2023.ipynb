{"cells":[{"cell_type":"markdown","id":"b11d90c2-46da-4a90-badc-deec8044970b","metadata":{"id":"b11d90c2-46da-4a90-badc-deec8044970b"},"source":["# **Linear Algebra for Data Science**: HW3, task 2  \n","# *Point cloud registration. Procrustes problem* (3 pts)\n","### <div align=\"right\"> &copy; Ostap Viniavskyi & Rostyslav Hryniv, 2023 </div>\n","\n","## Completed by:   \n","*   First team member\n","*   Second team member\n","\n","The aim of this task is find a rigid transformation that aligns two 3D objects (point clouds) in the best possible way. In the case when point pairs to be matched are given, this is known as Procrustes problem and can be solved via SVD. Otherwise, we will use the Iterative Closest Point (ICP) method that, in most cases, results in good alignment in several iterations"]},{"cell_type":"markdown","source":["#1. Introduction"],"metadata":{"id":"idWNqbDDcGVT"},"id":"idWNqbDDcGVT"},{"cell_type":"markdown","id":"3477b9e9-7140-40c2-9e69-bfe839050408","metadata":{"id":"3477b9e9-7140-40c2-9e69-bfe839050408"},"source":["A **point cloud** is a discrete set of data points in space. [Wiki](https://en.wikipedia.org/wiki/Point_cloud) \\\n","In this homework we will work with 3D point clouds representing a 3D shape or object. Each point is associated with its Cartesian coordinate $(X, Y, Z)$ in space and potentially some additional information, like RGB color, even though we would not use any here. Usually, 3D point cloud are obtained from LIDAR scans or from the 3D reconstuction from multiple views of the same scene or object.\n","\n","**Point cloud registration** is the problem of finding a spatial transformation (translation, rotation, scaling, etc.) that aligns two point sets. [Wiki](https://en.wikipedia.org/wiki/Point-set_registration)\n","\n","<div>\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fe/Cpd_fish_affine.gif\" width=\"300\"/>\n","</div>\n","\n","In this homework we will work with the case of the **rigid transformation in the 3D space**, meaning that the point clouds in question represent the same 3D rigid body in different positions in space.\n","\n","**Rigid-body motion in the 3D space** is represented by the 3x3 rotation matrix $R$ and 3D translation vector $T$. Rotation matrix $R$ belongs to the group of Special-Orthogonal Transformations $SO(3)$ - the group of orthogonal matrices with determinant equalt to $1$. (*Note: Orthogonal matrices whose determinant is equal to $-1$ represent such transformation in space that incorporates both rotation and reflection, the latter of which is not a valid transformation in 3D.*) More on 3D rotation representations and rigid body motion in general can be learnt from this amazing [lecture from the TUM](https://youtu.be/khLM8VV8LuM?list=PLTBdjV_4f-EJn6udZ34tht9EVIW7lbeo4).\n","\n","Moving to the problem in question, imagine that you have to program an algorithm for a robot to move objects from one point in 3D space to some target position. The robot has the ability to scan the environment around it and obtain the point cloud of the objects. Also, it is provided with some idealized model of the object already in the target position. The main challenge is to find how the scan of real object corresponds to its idealized model and find rigid transformation that provides best alignment.\n","\n","In the **data** directory you are provided with:\n","- `bottle_scan/*` -- the scanned water bottle textured mesh from which you can easily extract its point cloud\n","- `bottle-model.obj` -- the idealized water bottle mesh\n","- `bottle-model-samples-10k.obj` -- 10k points sampled uniformly on the surface of `bottle-model.obj` mesh in the initial location\n","- `bottle-model-samples-10k-target.obj` -- same 10k points as in previous file but in the target location\n","- `bottle-model-samples-8k.obj` -- another 8k points sampled uniformly on the surface of `bottle-model.obj` mesh in the initial location\n","\n","You can use any 3D viewer to explore the meshes in depth. We recommend using [MeshLab](https://www.meshlab.net/#download) - an open-source tool for 3D objects display and manipulation.\n","\n","From left to right: photo of the water bottle, scanned water bottle mesh with textures, point cloud of scanned water object, mesh of idealized bottle model, point cloud sampled on the surface of idealized model\n","\n","<table>\n","  <tr>\n","    <th>\n","      <div>\n","      <img src=\"https://drive.google.com/uc?export=view&id=1Mwi8Jtk6z0odkKqLfz1IB2C0IUBwq4gk\" height=\"500\" width=\"200\"/>\n","      </div>\n","    </th>\n","    <th>\n","      <div>\n","      <img src=\"https://drive.google.com/uc?export=view&id=1ak8HlcPLNJw2SKjgij4mxTHhQa_Pv8Ap\" height=\"500\" width=\"200\"/>\n","      </div>\n","    </th>\n","    <th>\n","      <div>\n","      <img src=\"https://drive.google.com/uc?export=view&id=1KFfoq0EaCViPPP6ad_aIE_dDiN-LHaX4\" height=\"450\" width=\"250\"/>\n","      </div>\n","    </th>\n","    <th>\n","      <div>\n","      <img src=\"https://drive.google.com/uc?export=view&id=1xyQRBZpAZky8BFihISwa-kxHSfbLFknK\" height=\"450\" width=\"200\"/>\n","      </div>\n","    </th>\n","    <th>\n","      <div>\n","      <img src=\"https://drive.google.com/uc?export=view&id=1fY37CHOC976dxn6KvOxIenv1l6nlZsli\" height=\"350\" width=\"200\"/>\n","      </div>\n","    </th>\n","  </tr>\n","</table>\n","\n","Already, you can see that the idealized model is not exactly the same as the scanned point cloud, and even the number of points is very different. Nevertheless, by carefully step-by-step designing our registration algorithm through the course of this and the next homework on optimization, we will try to align these two point clouds and find good-enough rigid transformation.\n","\n","Among other problems with point-cloud registration can be:\n","- partial occlusions;\n","- outlying points;\n","- scale differences.\n","\n","Yet, for simplicity we do not try to solve such cases in this homework. Indeed, classical methods are not very good at aligning partially occluded point clouds, thus Deep Learning methods come to help here."]},{"cell_type":"code","execution_count":null,"id":"17618955-5d9e-49da-a367-b366bd7e6992","metadata":{"id":"17618955-5d9e-49da-a367-b366bd7e6992"},"outputs":[],"source":["! pip install numpy matplotlib trimesh scipy tqdm"]},{"cell_type":"markdown","id":"214a1d11-d9b5-41b3-a08d-87db6ee1304b","metadata":{"id":"214a1d11-d9b5-41b3-a08d-87db6ee1304b"},"source":["# **Task 1 (1 pts)**: The case of known correspondences.\n","\n","We start with the simpler task of aligning two point cloud with known correspondences. They differ only by some unknown rigid-body transformation $R$ and $T$ that you have to find. The problem is known as Orthogonal procrustes problem as it requires finding an orthogonal 3D rotation matrix $R$.\n","\n","For this task we will use point cloud of an idealized model of the water bottle in two different positions in space. The points are sampled on the surface of the model once, and rotated/translated with some true $R$ and $T$ that you have to find. Thus we know exactly the correspondences between 10 thousand points in source and target point clouds.\n","\n","Here we will be working with the following two files:\n","- `bottle-model-samples-10k.obj` -- 10k points sampled uniformly on the surface of `bottle-model.obj` mesh in the source location\n","- `bottle-model-samples-10k-target.obj` -- 10k points sampled uniformly on the surface of `bottle-model.obj` mesh in the target location"]},{"cell_type":"code","execution_count":null,"id":"0bd3dfde-9f27-4b6d-b5ad-e2175d536b33","metadata":{"id":"0bd3dfde-9f27-4b6d-b5ad-e2175d536b33"},"outputs":[],"source":["from typing import Tuple, List\n","\n","import numpy as np\n","import trimesh\n","import matplotlib.pyplot as plt\n","import scipy\n","from mpl_toolkits.mplot3d import proj3d\n","from scipy.spatial.transform import Rotation\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"id":"774dde44-efa7-4de9-b01b-e3130e712dc2","metadata":{"id":"774dde44-efa7-4de9-b01b-e3130e712dc2"},"outputs":[],"source":["# read points in the source and target positions\n","def read_obj(fname: str) -> np.ndarray:\n","    \"\"\"Read .obj file containing point cloud using trimesh library.\"\"\"\n","    with open(fname) as f:\n","        data = trimesh.exchange.obj.load_obj(f)\n","    return data['vertices']\n","\n","src_fname = 'data/bottle-model-samples-10k.obj'\n","trg_fname = 'data/bottle-model-samples-10k-target.obj'\n","\n","pts_src = read_obj(src_fname)\n","pts_trg = read_obj(trg_fname)\n","pts_src.shape, pts_trg.shape"]},{"cell_type":"markdown","id":"e219593a-001a-4865-8995-af524813be0c","metadata":{"id":"e219593a-001a-4865-8995-af524813be0c"},"source":["Given two sets of corresponding points $x_i \\leftrightarrow y_i, i \\in {1\\dots M}, y_i \\in \\mathbb{R}^3, x_i \\in \\mathbb{R}^3$ we know that the points locations are related by the following equations:\n","$$y_i = Rx_i + T$$\n","Stacking all points into two $3\\times M$matrices $X$ and $Y$, we can write the equations simultaneously for all points:\n","$$Y = RX + T_{broadcasted}$$\n","where $T_{broadcasted}$ is also $3\\times M$ matrix of column vector $T$ horizontally stacked $M$ times\n","\n","In general, we assume that there is some noise present and try to find $R$ and $T$, such that the mean-squared error is minimized:\n","$$R, T = \\mbox{arg}\\min_{R', T'} \\sum_i ||y_i - R'x_i + T'||^2$$\n","\n","First, we can eliminate $T$ from the minimization problem and solve only for $R$. For this reason we normalize point clouds $X$ and $Y$ by subtracting their centroids $\\overline{x}$ and $\\overline{y}$  from each points in $X$ and $Y$ respectively.\n","Let's denote the resulting matrices $\\hat{X}$ and $\\hat{Y}$.\n","\n","\n","\n"]},{"cell_type":"markdown","source":["##**Task 1.1 (0.2 pts)**\n","Show that $\\hat{Y} = R\\hat{X}$.\n","\n","---\n","#### **YOUR DERIVATION HERE**\n","\n","---"],"metadata":{"id":"st38sROmam6V"},"id":"st38sROmam6V"},{"cell_type":"markdown","source":["Once we eliminated $T$, we only look for orthogonal $R$ (actually, special orthogonal R, but it doesn't matter to us now, since we know that true transformation is valid rotation). The problem becomes:\n","$$R = \\mbox{arg}\\min_{R'} \\sum_i||\\hat{y_i} - R'\\hat{x_i}||^2 = \\mbox{arg}\\min_{R'} ||R'\\hat{X_i} - \\hat{Y_i}||^2_F$$"],"metadata":{"id":"zUJx9tYla52J"},"id":"zUJx9tYla52J"},{"cell_type":"markdown","source":["---\n","##**Task 1.2 (0.4 pts)**\n","Prove that the $R$ that minimizes the above error function is $R = UV^T$, where $XY^T = U\\Sigma V^T$ is SVD of $3\\times 3$ matrix $YX^T$\n","\n","---\n","#### **YOUR DERIVATION HERE**\n","---\n","\n","Then $T$ can be recovered as $T = \\overline{y} - R\\overline{x}$\n","\n"],"metadata":{"id":"Tn4H4cjdaS3T"},"id":"Tn4H4cjdaS3T"},{"cell_type":"markdown","source":["---\n","##**Task 1.3 (0.4 pts)**\n","Implement solution to the Orthogonal procrustes problem given two sets of points  X  and  Y . You can rely on the numpy SVD solver."],"metadata":{"id":"UzJhKLV7blQ7"},"id":"UzJhKLV7blQ7"},{"cell_type":"code","execution_count":null,"id":"8334105a-4d66-4662-82e1-7df08579065e","metadata":{"id":"8334105a-4d66-4662-82e1-7df08579065e"},"outputs":[],"source":["def orthogonal_procrustes(X: np.ndarray, Y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Implementation of Orthogonal procrustes problem\n","    Args:\n","        X: 3D points from the first point cloud; shape: (3, M)\n","        Y: 3D points from the second point cloud; shape: (3, M)\n","\n","    Returns:\n","        R: rotation matrix; shape: (3, 3)\n","        T: translation vector; shape: (3, )\n","    \"\"\"\n","    # =========== YOUR CODE STARTS HERE ============\n","    R, T = ..., ...\n","    # =========== YOUR CODE ENDS HERE ==============\n","    return R, T\n","\n","R_pred, T_pred = orthogonal_procrustes(X=pts_src.T, Y=pts_trg.T)\n","r_euler = Rotation.from_matrix(R_pred).as_euler('xyz', degrees=True)\n","print(f'Predicted rotation: X={r_euler[0]:.3}deg, Y={r_euler[1]:.3}deg, Z={r_euler[2]:.3}deg')\n","print(f'Predicted translation: X={T_pred[0]:.3}m, Y={T_pred[1]:.3}m, Z={T_pred[2]:.3}m')\n"]},{"cell_type":"code","execution_count":null,"id":"90c37943-899a-40ed-b771-b719c03f653d","metadata":{"id":"90c37943-899a-40ed-b771-b719c03f653d"},"outputs":[],"source":["# plot predictions X - in blue, Y - in read\n","def plot_predictions(X, Y, R, T):\n","\n","    X = X @ R.T + T\n","\n","    fig = plt.figure(figsize=(17, 17))\n","    ax = fig.add_subplot(121, projection='3d')\n","    ax.scatter(X[:, 0], X[:, 1], X[:, 2], s=2., alpha=0.5)\n","\n","    # ax = fig.add_subplot(122, projection='3d')\n","    ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c='r', s=2., alpha=0.5)\n","    plt.legend(['X', 'Y'])\n","\n","    plt.title('Points clouds X and Y aligned by predicted R_pred, T_pred')\n","\n","    plt.show()\n","\n","plot_predictions(pts_src, pts_trg, R_pred, T_pred)"]},{"cell_type":"markdown","id":"0e14f1fd-b75e-4bc2-bdbe-297bf51ec5a5","metadata":{"id":"0e14f1fd-b75e-4bc2-bdbe-297bf51ec5a5"},"source":["# **Task 2 (2 pts)**: Case of unknown correspondences.\n","\n","In this task we will continue to work with model of water bottle. In contrast to the previous problem we will not assume known correspondences, nor equal number of points in source and target point clouds. To simulate this scenario we will sample points on the surface of mesh twice: once 10k points and once 8k points. We will assume some manually specified rigid transformation on the second points cloud and explore how it affects the results of the algorithm.\n","\n","\n","Here we will be working with the following two files:\n","- `bottle-model-samples-10k.obj` -- 10k points sampled uniformly on the surface of `bottle-model.obj` mesh in the initial location\n","- `bottle-model-samples-8k.obj` -- 8k points sampled uniformly on the surface of `bottle-model.obj` mesh in the initial location\n","\n","Next we will use **Iterative Closest Points (ICP)** algorithm to iteratively find the optimal rigid motion. The algorithm switches between 2 steps:\n","- finding matching between two sets --> for each $x_i$ in $X$ we find $y_{n_i}$ in the set $Y$ such that $||Rx_i + T - y_{n_i}||^2$ is minimal among all $y_j, j \\in 1\\dots N$ for current rotation estimate $R$ and translation estimate $T$.\n","- solving orthogonal Procrustes problem for the established correspondences to update $R$ and $T$.\n","\n","We can define the point-to-point error measure in terms of Mean Squared Error between matched points.\n","$MSE(R, T) = \\frac{1}{n} \\sum_i ||Rx_i + T - y_{n_i}||^2$, where $y_{n_i}$ is the correspondence of $x_i$ as defined above.\n","Note that each point in $Y$ can be matched with multiple points in $X$.\n","\n","Repeating those steps, until the error decreases in one iteration less than some threshold $\\tau$, will allow us to monotonically decrease the error on each step and converge to a solution. However, the solution is not guaranteed to be the optimal one as the algorithm **may get stuck in the local minima**.\n","\n"]},{"cell_type":"markdown","source":["---\n","##**Task 2.1 (0.8 pts)**\n","Prove that MSE is guaranteed to monotonically decrease or stay the same on each step of ICP.\n","\n","---\n","#### **YOUR PROOF HERE**\n","\n","---\n"],"metadata":{"id":"JtZgeEIedAzD"},"id":"JtZgeEIedAzD"},{"cell_type":"markdown","source":["---\n","##**Task 2.2 (1.2 pts)**\n","Implement solution to the ICP given two sets of points $X$ and $Y$. You can rely on your previous Orthogonal procrustes solver.\n","Test your solution like the following:\n","1. Generate ground truth rotations $R_{gt}$ around X-axis with the angles from $0^\\circ$ to $355^\\circ$ with the step $10^\\circ$ and apply it along with provided translation $T_{gt}$ to the `bottle-model-samples-8k.obj` point cloud. You can use scipy rotation representations convertor to obtain rotation matrix from axis-angle representation.\n","2. Try to estimate the rotation and translation between `bottle-model-samples-10k.obj` and transformed `bottle-model-samples-8k.obj` using your ICP implementation.\n","3. Calculate rotation and translation error for each ground truth rotation angle and plot the graphs with angle on the x-axis and error in the y-axis. Code for error calculation will be provided to you. Also plot mse-loss histories and predicted points clouds for the angles of $60^\\circ$ and $180^\\circ$.\n","4. Comment on the result. Why the error is nearly 180 degrees after the true rotation exceeds 90 degrees?\n","\n","- find_optimal_correspondences - 0.3 pts\n","- icp (optimization loop) - 0.3 pts\n","- testing on multiple ground truth rotation angles - 0.2 pts\n","- plots and comments - 0.4 pts\n"],"metadata":{"id":"mXnl8CGjct1C"},"id":"mXnl8CGjct1C"},{"cell_type":"code","execution_count":null,"id":"4bc7bc63-07f5-416c-8eaf-0f3788805ec9","metadata":{"id":"4bc7bc63-07f5-416c-8eaf-0f3788805ec9"},"outputs":[],"source":["def find_optimal_correspondences(X: np.ndarray, Y: np.ndarray,\n","                                 R: np.ndarray, T: np.ndarray) -> Tuple[np.ndarray, float]:\n","    \"\"\"\n","    Finds closest point from Y for each point in the point cloud X transformed by motion (R, T)\n","    Also compute mean square error between each transformed point in X and nearest neighbor in Y\n","    Args:\n","        X: 3D points from the first point cloud; shape: (3, M)\n","        Y: 3D points from the second point cloud; shape: (3, N)\n","        R: current rotation estimate\n","        T: current translation estimate\n","\n","    Returns:\n","        Y_nn: nearest neighbors from Y for each point in transformed X; shape (3, M)\n","        J: mean square error\n","    \"\"\"\n","    # =========== YOUR CODE STARTS HERE ============\n","\n","    # =========== YOUR CODE ENDS HERE ==============\n","    return Y_nn, J\n","\n","def icp(X: np.ndarray, Y: np.ndarray, tau: float = 1e-6) -> Tuple[np.ndarray, np.ndarray, List[float]]:\n","    \"\"\"\n","    Implementation of ICP for registration of unmatched point cloud of potentially different sizes\n","    Args:\n","        X: 3D points from the first point cloud; shape: (3, M)\n","        Y: 3D points from the second point cloud; shape: (3, N)\n","        tau: error decrease threshold used as stopping criterion\n","    Returns:\n","        R: rotation matrix; shape: (3, 3)\n","        T: translation vector; shape: (3, ),\n","        loss_history: list of MSE value at each iteration\n","    \"\"\"\n","    # init rotation with identity and rotation with the vector between center of point clouds\n","    R, T = np.eye(3), Y.mean(1) - X.mean(1)\n","    # compute initial correspondences\n","    Y_nn, J = find_optimal_correspondences(X, Y, R, T)\n","    loss_history = [J]\n","    # =========== YOUR CODE STARTS HERE ============\n","    # OPTIMIZATION LOOP HERE\n","    # =========== YOUR CODE ENDS HERE ==============\n","    return R, T, loss_history"]},{"cell_type":"code","execution_count":null,"id":"a467a8cb-2c6b-47f6-884e-a218b28d1315","metadata":{"id":"a467a8cb-2c6b-47f6-884e-a218b28d1315"},"outputs":[],"source":["# error metrics\n","def rigid_motion_error(R_true: np.ndarray, R_pred: np.ndarray,\n","                       T_true: np.ndarray, T_pred: np.ndarray) -> Tuple[float, float]:\n","    \"\"\"\n","    Calculate error in rigid body motion: rotation and translation separately.\n","    For rotation compute minimal angle that transforms one rotation into other.\n","    For translation simply compute distance between two vectors.\n","    Args:\n","        R_true: true rotation; shape: (3, 3)\n","        R_pred: predicted rotation; shape: (3, 3)\n","        T_true: true translation; shape: (3,)\n","        T_pred: predicted translation; shape: (3,)\n","    Returns:\n","        rot_err: error in rotation in angles\n","        trans_err: error in translation in meters (or any other units)\n","    \"\"\"\n","    cos = (np.trace(np.dot(R_true.T, R_pred)) - 1) / 2\n","    cos = np.clip(cos, -1., 1.)  # numercial errors can make it out of bounds\n","    rot_err = np.rad2deg(np.abs(np.arccos(cos)))\n","    trans_err = np.linalg.norm(T_true - T_pred)\n","    return rot_err, trans_err"]},{"cell_type":"code","execution_count":null,"id":"81a1b37a-9520-471c-b6ca-b81142002318","metadata":{"id":"81a1b37a-9520-471c-b6ca-b81142002318"},"outputs":[],"source":["# experimets part\n","src_fname = 'data/bottle-model-samples-10k.obj'\n","trg_fname = 'data/bottle-model-samples-8k.obj'\n","\n","pts_src = read_obj(src_fname)\n","pts_trg = read_obj(trg_fname)\n","print(pts_src.shape, pts_trg.shape)\n","# axis of rotation - X\n","axis = np.array([1., 0., 0.])\n","# ground  truth translation\n","T_gt = np.array([0.5, 0.6, 0.7])\n","\n","# angles\n","angles = [i * 10 for i in range(36)]\n","rot_errors = []\n","trans_errors = []\n","loss_histories = []\n","\n","# =========== YOUR CODE STARTS HERE ============\n","\n","# =========== YOUR CODE ENDS HERE =============="]},{"cell_type":"markdown","id":"8fea8c38-d84d-4fea-b540-833b6a9e77c3","metadata":{"id":"8fea8c38-d84d-4fea-b540-833b6a9e77c3"},"source":["# **Task 3 (0.3 pts)**: Test on the real world scan.\n","\n","Here we will test our algorithm on the provided scan.\n","\n","We will be working with the following two files:\n","- `bottle-scan/textured_output.obj` -- textured mesh of scanned object.\n","- `bottle-model-samples-10k-target.obj` -- 10k points sampled uniformly on the surface of `bottle-model.obj` mesh in the target location\n","\n"]},{"cell_type":"markdown","source":["##**Task 3.1 (0.3 pts)**\n","Test ICP algorithm on real world scan and idealized model as a target. Report the results numerically and visually. Comment on the results."],"metadata":{"id":"rTV3eHlKdi0f"},"id":"rTV3eHlKdi0f"},{"cell_type":"code","execution_count":null,"id":"c86ec7a5-334e-494c-8f3a-db02b99cb7da","metadata":{"id":"c86ec7a5-334e-494c-8f3a-db02b99cb7da"},"outputs":[],"source":["src_fname = 'data/bottle_scan/textured_output.obj'\n","trg_fname = 'data/bottle-model-samples-10k-target.obj'\n","pts_src = read_obj(src_fname)\n","pts_trg = read_obj(trg_fname)\n","print(pts_src.shape, pts_trg.shape)\n","\n","# =========== YOUR CODE STARTS HERE ===========\n","R_pred, T_pred, loss_history = icp(X=pts_src.T, Y=pts_trg.T, tau=1e-4)\n","r_euler = Rotation.from_matrix(R_pred).as_euler('xyz', degrees=True)\n","\n","print(f'Predicted rotation: X={r_euler[0]:.3}deg, Y={r_euler[1]:.3}deg, Z={r_euler[2]:.3}deg')\n","print(f'Predicted translation: X={T_pred[0]:.3}m, Y={T_pred[1]:.3}m, Z={T_pred[2]:.3}m')\n","\n","plt.plot(loss_history)\n","plt.xlabel('Iteration')\n","plt.ylabel('MSE')\n","plt.title('MSE optimization history');\n","# =========== YOUR CODE ENDS HERE =============="]},{"cell_type":"markdown","id":"defae3e3-8ca4-49e7-82ed-34dc1be010a5","metadata":{"id":"defae3e3-8ca4-49e7-82ed-34dc1be010a5"},"source":["# Conclusions (0.2 pts)\n","Comment on the work done in this homework and algorithms implemented. State their advantages and limitations.\n","\n","---\n","**YOUR COMMENTS HERE**\n","\n","---"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}